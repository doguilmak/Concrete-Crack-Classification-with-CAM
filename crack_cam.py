# -*- coding: utf-8 -*-
"""Crack_CAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18DDBm-RRGT79G7OzsLiLVHbNx6-1JSL6

<h1 align=center><font size = 6>Concrete Crack Classification with Class Activation Map</font></h1>
<br>
<img src="https://raw.githubusercontent.com/doguilmak/Concrete-Crack-Classification-with-CAM/main/concrete_crack_wp.png" height=520 width=1000 alt="britannica.com">
<small>Picture Source:<a href="https://github.com/doguilmak"> Doğu İlmak Github</a>

<br>

<h2>Description</h2>
<p>The dataset contains concrete images having cracks. The data is collected from various <b>METU Campus Buildings</b>.
The dataset is divided into two as negative and positive crack images for image classification. 
Each class has 20000images with a total of 40000 images with <i>227 x 227</i> pixels with RGB channels. 
The dataset is generated from 458 high-resolution images (4032x3024 pixel) with the method proposed by Zhang et al (2016). 
High-resolution images have variance in terms of surface finish and illumination conditions. 
No data augmentation in terms of random rotation or flipping is applied.</p>

<br>

<h2>Acknowledgements</h2>
<p>This dataset has been referred from <a href="https://data.mendeley.com/datasets/5y9wdsg2zt/2">data.mendeley.com</a>. 

<i>If you use this dataset please cite: 
2018 – Özgenel, Ç.F., Gönenç Sorguç, A. “Performance Comparison of Pretrained Convolutional Neural Networks on Crack Detection in Buildings”, ISARC 2018, Berlin.</i></p>

<br>

<h2>License</h2>
<p>CC BY 4.0
The files associated with this dataset are licensed under a Creative Commons Attribution 4.0 International license.
What does this mean?

You can share, copy and modify this dataset so long as you give appropriate credit, provide a link to the CC BY license, and indicate if changes were made, but you may not do so in a way that suggests the rights holder has endorsed you or your use of the dataset. Note that further permission may be required for any content within the dataset that is identified as belonging to a third party.</p>

<br>

<h2>Objective:</h2>
<ul>
  <li>Understand the dataset & cleanup (if required).</li>
  <li>Build classification models to predict the concrete class.</li>
  <li>Also fine-tune the hyperparameters & compare the evaluation metrics of various classification algorithms.</li>
  <li>Build class activation maps (CAM).</li>
</ul>

<br>
<h2>Keywords</h2>
<ul>
  <li>Computer Science</li>
  <li>Classification</li>
  <li>Structure</li>
  <li>Class Activation Map</li>
  <li>Neural Networks</li>
  <li>Concrete (Composite Building Material)</li>
  <li>Concrete Cracking</li>
</ul>
<br>

<h2>Objective for this Notebook</h2>

<p>Within the scope of this project, a classification model was builded whether if there is any crack or not through data obtained from <b>Middle East Technical University</b>.</p>
<div class="alert alert-block alert-info" style="margin-top: 20px">

<li><a href="https://#import">Import Libraries and Packages</a></li>
<li><a href="https://#data_preparation">Dataset Preparation</a></li>
<li><a href="https://#compile_fit">Compile and Fit the Model</a></li>
<li><a href="https://#build_cam">Building Class Activation Maps</a></li>
<li><a href="https://#make_dataframe">Make Dataframe for the Predictions</a></li>
<li><a href="https://#upload_predict">Upload and Predict Your Picture!</a></li>
<br>

<p></p>
Estimated Time Needed: <strong>30 min</strong>
</div>
"""

!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week4.zip

!unzip -q concrete_data_week4.zip

"""<br>
<h2 align=center id="import">Import Libraries and Packages</h2>
<p>The following are the libraries we are going to use for this lab:</p>
"""

#from tensorflow.keras.applications.resnet50 import preprocess_input
import tensorflow as tf
from tensorflow.keras import layers

from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model, load_model
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D
from keras.applications.vgg16 import preprocess_input

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
import cv2
import seaborn as sns

import os
import shutil

import datetime

"""<br>
<h2 align=center id="data_preparation">Dataset Preparation</h2>

<p>We are going to separate our dataset.</p>
"""

num_classes = 2
image_resize = 224
batch_size_training = 100
batch_size_validation = 100

data_generator = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)

train_generator = data_generator.flow_from_directory(
  "concrete_data_week4/train",
  target_size=(image_resize, image_resize),
  batch_size=batch_size_training,
  class_mode='categorical')

validation_generator = data_generator.flow_from_directory(
  "concrete_data_week4/valid",
  target_size=(image_resize, image_resize),
  batch_size=batch_size_validation,
  class_mode='categorical')

"""<p>Let's plot our first 4 images in the batch and print batches.</p>"""

first_batch = train_generator.next()
first_batch

first_batch_images = train_generator.next()[0]
first_batch_images

fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 10)) # define your figure and axes

ind = 0
for ax1 in axs:
    for ax2 in ax1: 
        image_data = first_batch_images[ind]
        #image_data = first_batch_images[ind].astype(np.uint8)
        ax2.imshow(image_data)
        ind += 1

fig.suptitle('First Batch of Concrete Images') 
plt.show()

second_batch_images=train_generator.next()[0]
print(second_batch_images)

third_batch_images=train_generator.next()[0]
print(third_batch_images)

fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 10)) # define your figure and axes

ind = 0
for ax1 in axs:
    for ax2 in ax1: 
        image_data = third_batch_images[ind]
        #image_data = third_batch_images[ind].astype(np.uint8)
        ax2.imshow(image_data)
        ind += 1

fig.suptitle('Third Batch of Concrete Images') 
plt.show()

fourth_batch_labels=train_generator.next()[1]
print("Negative (no cracks): ", sum(fourth_batch_labels[:, 0:1]))
print("Positive (with cracks): ", sum(fourth_batch_labels[:, 1:2]))
print(fourth_batch_labels)
print(len(fourth_batch_labels))

fifth_batch_images=train_generator.next()
plt.imshow(fifth_batch_images[0][1])
plt.title('Second image in the Fifth Batch')
plt.show()

fifth_batch_images[1]

"""<br>
<h2 align=center id="compile_fit">Compile and Fit the Model</h2>
"""

#load_model('/content/model.h5')

def model_block(inputs, num_classes):
 
  model = Sequential([
    
    layers.Conv2D(16, input_shape=(image_resize, image_resize, 3), kernel_size=(3,3),activation='relu',padding='same'),        
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'),
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),
    layers.MaxPooling2D(pool_size=(2,2)),

    layers.Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),
    layers.GlobalAveragePooling2D(),
    layers.Dense(num_classes, activation='softmax')
  
  ])
  model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=tf.keras.optimizers.RMSprop(lr=0.001))
  model.summary()
  
  return model

model = model_block(224, 2) # 224x224 as pixels and 2 as crack classes

num_epochs = 2
steps_per_epoch_training = len(train_generator)
steps_per_epoch_validation = len(validation_generator)

history = model.fit_generator(
    train_generator,
    steps_per_epoch=steps_per_epoch_training,
    epochs=num_epochs,
    validation_data=validation_generator,
    validation_steps=steps_per_epoch_validation,
    verbose=1,
)

plt.figure(figsize=(20, 10))
sns.set_style('whitegrid')
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Concrete Crack Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['accuracy', 'val_accuracy'], loc='upper left')
plt.show()

plt.figure(figsize=(20, 10))
sns.set_style('whitegrid')
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Concrete Crack Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['loss', 'val_loss'], loc='upper left')
plt.show()

model.save("model.h5")
print("Model saved!")

"""<br>
<h2 align=center id="build_cam">Building Class Activation Maps</h2>
"""

# select all the layers for which you want to visualize the outputs and store it in a list
outputs = [layer.output for layer in model.layers[1:9]]

# Define a new model that generates the above output
vis_model = Model(model.input, outputs)

# store the layer names we are interested in
layer_names = []
for layer in outputs:
    layer_names.append(layer.name.split("/")[0])

    
print("Layers that will be used for visualization: ")
print(layer_names)

gap_weights = model.layers[-1].get_weights()[0]
gap_weights.shape

cam_model  = Model(inputs=model.input, outputs=(model.layers[-3].output,model.layers[-1].output))
cam_model.summary()

class_mapping = train_generator.class_indices
class_mapping

def show_cam(image_value, features, results):
  '''
  Displays the class activation map of an image

  Args:
    image_value (tensor) -- preprocessed input image with size 224 x 224
    features (array) -- features of the image, shape (1, 28, 28, 128)
    results (array) -- output of the sigmoid layer
  '''

  # there is only one image in the batch so we index at `0`
  features_for_img = features[0]
  prediction = results[0]

  # there is only one unit in the output so we get the weights connected to it
  class_activation_weights = gap_weights[:,0]

  # upsample to the image size
  class_activation_features = sp.ndimage.zoom(features_for_img, (224/28, 224/28, 1), order=2)
  
  # compute the intensity of each feature in the CAM
  cam_output  = np.dot(class_activation_features,class_activation_weights)

  # visualize the results
  print(f'Output \nWithout Crack Probability: {results[0][0]} \nCrack Probability: {results[0][1]}')
  plt.figure(figsize=(8, 8))
  plt.imshow(cam_output, cmap='jet', alpha=0.5)
  plt.imshow(tf.squeeze(image_value), alpha=0.5)
  plt.show()

def convert_and_classify(image):

  # load the image
  img = cv2.imread(image)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

  # preprocess the image before feeding it to the model
  img = cv2.resize(img, (224, 224)) / 255.0

  # add a batch dimension because the model expects it
  tensor_image = np.expand_dims(img, axis=0)

  # get the features and prediction
  features,results = cam_model.predict(tensor_image)
  
  # generate the CAM
  show_cam(tensor_image, features, results)

convert_and_classify('/content/concrete_data_week4/test/negative/19751.jpg')

convert_and_classify('/content/concrete_data_week4/test/positive/19751.jpg')

"""<br>
<h2 align=center id="make_dataframe">Make Dataframe for the Predictions</h2>
"""

test_generator = data_generator.flow_from_directory(
  '/content/concrete_data_week4/test',
  target_size=(image_resize, image_resize),
  shuffle=False,
  class_mode='categorical')

filenames=test_generator.filenames

pred=model.predict_generator(test_generator, steps=len(test_generator), verbose=1).round(3)

filenames_df = pd.DataFrame(filenames, columns=['File Path'])
pred_df = pd.DataFrame(pred, columns=['Without Crack Probability', 'Crack Probability'])
model_predictions = pd.concat([filenames_df, pred_df], axis=1)
model_predictions

file_name='model_predictions.csv'
model_predictions.to_csv(file_name, sep=',', encoding='utf-8')

"""<br>
<h2 align=center id="upload_predict">Upload and Predict Your Picture!</h2>
"""

from google.colab import files
from keras.preprocessing import image
from numpy import asarray

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  width = 224
  height = 224
  dim = (width, height)
  path = '/content/' + fn
  img = cv2.imread(path)
  convert_and_classify(path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  img = cv2.resize(img, dim)
  x = asarray(img)
  x = np.expand_dims(x, axis=0)

  image_tensor = np.vstack([x])
  classes = model.predict(image_tensor)
  print("Without Crack Probability: %", round(classes[0][0]*100, 2))
  print("Crack Probability: %", round(classes[0][1]*100, 2))

"""<h1>Contact Me</h1>
<p>If you have something to say to me please contact me:</p>

<ul>
  <li>Twitter: <a href="https://twitter.com/Doguilmak">Doguilmak</a></li>
  <li>Mail address: doguilmak@gmail.com</li>
</ul>
"""

from datetime import datetime
print(f"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")